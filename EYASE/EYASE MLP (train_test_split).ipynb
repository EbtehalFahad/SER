{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ada653cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile, librosa, pickle, glob, os, parselmouth, pywt, statistics, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as geek\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# all emotions on RAVDESS dataset\n",
    "allemotion = {\n",
    "    \"neu\": \"neutral\",\n",
    "    \"hap\": \"happy\",\n",
    "    \"sad\": \"sad\",\n",
    "    \"ang\": \"angry\"\n",
    "}\n",
    "# all gender on  dataset\n",
    "allgender = {\n",
    "    \"ml\": \"male\",\n",
    "    \"fm\": \"female\"\n",
    "}\n",
    "# Emotions to observe\n",
    "observed_emotions={\n",
    "    \"angry\",\n",
    "    #\"sad\",\n",
    "    \"neutral\",\n",
    "    #\"happy\"\n",
    "}\n",
    "# gender to observe\n",
    "observed_gender={\n",
    "    \"male\",\n",
    "    \"female\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a7ba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract features (mfcc, mel, ....) from a sound file\n",
    "def extract_file_features(file_name, gender, **kwargs):  \n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    \n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        sound = parselmouth.Sound(file_name) # read the sound\n",
    "        \n",
    "        \n",
    "        # Spectral features (MFCC, Mel, LTAS)       \n",
    "        # MFCC:\n",
    "        mfcc = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=12).T, axis=0)\n",
    "        # Mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        # LTAS\n",
    "        spectrum = sound.to_spectrum()\n",
    "        ltas = call(spectrum, \"To Ltas (1-to-1)\")\n",
    "        ltas_mean = call(ltas, \"Get mean\", 0, 0, \"dB\") \n",
    "        ltas_sd = call(ltas, \"Get standard deviation\", 0, 0, \"dB\")\n",
    "        ltas_max = call(ltas, \"Get maximum\", 0, 0, \"parabolic\")\n",
    "        ltas_min = call(ltas, \"Get minimum\", 0, 0, \"parabolic\")\n",
    "        ltas_range = ltas_max - ltas_min\n",
    "        ltas_slope = call(ltas, \"Get slope\", 0, 1000, 1000, 4000.0, \"dB\")\n",
    "        # Formants\n",
    "        formant= sound.to_formant_burg()\n",
    "        f1_mean = call(formant, \"Get mean\", 1, 0, 0, \"Hertz\") # get mean 1st Formant\n",
    "        f2_mean = call(formant, \"Get mean\", 2, 0, 0, \"Hertz\") # get mean 2st Formant\n",
    "        f3_mean = call(formant, \"Get mean\", 3, 0, 0, \"Hertz\") # get mean 3st Formant\n",
    "        f1_sd = call(formant, \"Get standard deviation\", 1, 0, 0, \"Hertz\") # get standard deviation 1st Formant\n",
    "        f2_sd = call(formant, \"Get standard deviation\", 2, 0, 0, \"Hertz\") # get standard deviation 2st Formant\n",
    "        f3_sd = call(formant, \"Get standard deviation\", 3, 0, 0, \"Hertz\") # get standard deviation 3st Formant       \n",
    "\n",
    "        # Prosodic features (pitch, intensity, formant, Jitter, Shimmer,,, HNR, Jitter, Shimmer)\n",
    "        # Pitch\n",
    "        if gender == \"male\":\n",
    "            pitch = call(sound, \"To Pitch\", 0, 75, 300) #create a praat pitch object\n",
    "        if gender == \"female\":\n",
    "            pitch = call(sound, \"To Pitch\", 0, 100, 500) #create a praat pitch object\n",
    "        \n",
    "        #pitch = sound.to_pitch()\n",
    "        pitch_mean = call(pitch, \"Get mean\", 0, 0, \"Hertz\") \n",
    "        pitch_sd = call(pitch, \"Get standard deviation\", 0 ,0, \"Hertz\") \n",
    "        pitch_max = call(pitch, \"Get maximum\", 0, 0, \"Hertz\", \"Parabolic\") \n",
    "        pitch_min = call(pitch, \"Get minimum\", 0, 0, \"Hertz\", \"Parabolic\")\n",
    "        pitch_range = pitch_max - pitch_min\n",
    "        \n",
    "        # Intensity\n",
    "        intensity = sound.to_intensity() \n",
    "        intensity_mean = call(intensity, \"Get mean\", 0, 0) \n",
    "        intensity_sd = call(intensity, \"Get standard deviation\", 0 ,0) \n",
    "        intensity_max = call(intensity, \"Get maximum\", 0, 0, \"Parabolic\")\n",
    "        intensity_min = call(intensity, \"Get minimum\", 0, 0, \"Parabolic\") \n",
    "        intensity_range = intensity_max - intensity_min\n",
    "        \n",
    "        # HNR\n",
    "        harmonicity = sound.to_harmonicity() #create a praat harmonicity object\n",
    "        hnr = call(harmonicity, \"Get mean\", 0, 0) # get Harmonic to Noise Ratio\n",
    " \n",
    "        #duration\n",
    "        duration = sound.get_end_time()\n",
    "\n",
    "        # Jitter and shimmer  \n",
    "        pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75.0, 600.0)\n",
    "        #jitter\n",
    "        localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3) # local Jitter\n",
    "        localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3) # local-absolute Jitter\n",
    "        rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3) # rap Jitter\n",
    "        ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3) # ppq5 Jitter\n",
    "        ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3) # ddp Jitter\n",
    "        #Shimmer\n",
    "        localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # local Shimmer\n",
    "        localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # local-db Shimmer\n",
    "        apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # apq3 Shimmer\n",
    "        aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # aqpq5S himmer\n",
    "        apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # apq11 Shimmer\n",
    "        ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # dda Shimmer\n",
    "      \n",
    "   \n",
    "        return mfcc, mel, ltas_mean, ltas_sd, ltas_max, ltas_min, ltas_range, ltas_slope, f1_mean, f1_sd, f2_mean, f2_sd, f3_mean, f3_sd, pitch_mean, pitch_sd, pitch_max, pitch_min, pitch_range, intensity_mean, intensity_sd, intensity_max, intensity_min, intensity_range, hnr, duration,localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ec17da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPCA(df, t):\n",
    "    #Z-score the Jitter and Shimmer measurements\n",
    "    if t==\"jitter\":\n",
    "        features = ['local Jitter', 'local-absolute Jitter', 'rap Jitter', 'ppq5 Jitter', 'ddp Jitter']\n",
    "    if t==\"shimmer\":\n",
    "        features = ['local Shimmer', 'local-db Shimmer', 'apq3 Shimmer', 'apq5 Shimmer', 'apq11 Shimmer', 'dda Shimmer']\n",
    "      \n",
    "    # Separating out the features\n",
    "    x = df.loc[:, features].values\n",
    "    \n",
    "    # Standardizing the features\n",
    "    x = StandardScaler().fit_transform(x)   \n",
    "\n",
    "    #PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    \n",
    "    #PCA_list = principalComponents.tolist()\n",
    "    if t==\"jitter\":\n",
    "        principalDf = pd.DataFrame(data = principalComponents, columns = ['Jitter PCA'])\n",
    "        pcalist = principalComponents.tolist()\n",
    "    if t==\"shimmer\":\n",
    "        principalDf = pd.DataFrame(data = principalComponents, columns = ['shimmer PCA'])\n",
    "        pcalist = principalComponents.tolist()\n",
    "\n",
    "    return principalDf, pcalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d6e009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to put the results\n",
    "file_list, speaker_list, gender_list, emotion_list = [], [], [], []\n",
    "jitterpca_list = []\n",
    "shimmerpca_list = []\n",
    "mfcc_list, mel_list = [], []\n",
    "ltas_mean_list, ltas_sd_list, ltas_max_list, ltas_min_list, ltas_range_list, ltas_slope_list =  [], [], [], [], [], []\n",
    "f1_mean_list, f1_sd_list, f2_mean_list, f2_sd_list, f3_mean_list, f3_sd_list =  [], [], [], [], [], []\n",
    "pitch_mean_list, pitch_sd_list, pitch_max_list, pitch_min_list, pitch_range_list =  [], [], [], [], []\n",
    "intensity_mean_list, intensity_sd_list, intensity_max_list, intensity_min_list, intensity_range_list =  [], [], [], [], []\n",
    "hnr_list, duration_list =  [], []\n",
    "localJitter_list, localabsoluteJitter_list, rapJitter_list, ppq5Jitter_list, ddpJitter_list = [], [], [], [], []\n",
    "localShimmer_list, localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, apq11Shimmer_list, ddaShimmer_list = [], [], [], [], [], []\n",
    "\n",
    "\n",
    "# Load the data\n",
    "def extract_all_features():\n",
    "    \n",
    "    for file in glob.glob(\"EYASE/*/*.wav\", recursive=True): #, recursive=True\n",
    "        # get the base name of the audio file\n",
    "        basename = os.path.basename(file)\n",
    "        # get the emotion label\n",
    "        emotion = allemotion[basename.split(\"_\")[1].split(\" \")[0]]\n",
    "        # get the gender label\n",
    "        gender = allgender[basename.split(\"_\")[0][0:2]]\n",
    "        # get the speaker label\n",
    "        speaker = basename.split(\"_\")[0][0:4]\n",
    "    \n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        if gender not in observed_gender:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        # extract speech features\n",
    "        (mfcc, mel, ltas_mean, ltas_sd, ltas_max, ltas_min, ltas_range, ltas_slope, \n",
    "         f1_mean, f1_sd, f2_mean, f2_sd, f3_mean, f3_sd, pitch_mean, pitch_sd, pitch_max, pitch_min, pitch_range, \n",
    "         intensity_mean, intensity_sd, intensity_max, intensity_min, intensity_range, hnr, duration, localJitter, \n",
    "         localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, \n",
    "         apq11Shimmer, ddaShimmer) = extract_file_features(file, gender, mfcc=True, chroma=True, mel=True)   \n",
    "        \n",
    "        file_list.append(basename) # make an ID list\n",
    "        speaker_list.append(speaker)\n",
    "        gender_list.append(gender)\n",
    "        emotion_list.append(emotion)\n",
    "        mfcc_list.append(mfcc) # make a MFCCs list\n",
    "        mel_list.append(mel) # make a Mel list\n",
    "        ltas_mean_list.append(ltas_mean)\n",
    "        ltas_sd_list.append(ltas_sd)\n",
    "        ltas_max_list.append(ltas_max)\n",
    "        ltas_min_list.append(ltas_min)\n",
    "        ltas_range_list.append(ltas_range)\n",
    "        ltas_slope_list.append(ltas_slope)\n",
    "        f1_mean_list.append(f1_mean) \n",
    "        f1_sd_list.append(f1_sd)\n",
    "        f2_mean_list.append(f2_mean)\n",
    "        f2_sd_list.append(f2_sd)\n",
    "        f3_mean_list.append(f3_mean)\n",
    "        f3_sd_list.append(f3_sd)      \n",
    "        pitch_mean_list.append(pitch_mean)\n",
    "        pitch_sd_list.append(pitch_sd)\n",
    "        pitch_max_list.append(pitch_max)\n",
    "        pitch_min_list.append(pitch_min)\n",
    "        pitch_range_list.append(pitch_range)\n",
    "        intensity_mean_list.append(intensity_mean)\n",
    "        intensity_sd_list.append(intensity_sd)\n",
    "        intensity_max_list.append(intensity_max)\n",
    "        intensity_min_list.append(intensity_min)\n",
    "        intensity_range_list.append(intensity_range)\n",
    "        hnr_list.append(hnr)\n",
    "        duration_list.append(duration)\n",
    "        localJitter_list.append(localJitter)\n",
    "        localabsoluteJitter_list.append(localabsoluteJitter)\n",
    "        rapJitter_list.append(rapJitter)\n",
    "        ppq5Jitter_list.append(ppq5Jitter)\n",
    "        ddpJitter_list.append(ddpJitter)\n",
    "        localShimmer_list.append(localShimmer)\n",
    "        localdbShimmer_list.append(localdbShimmer)\n",
    "        apq3Shimmer_list.append(apq3Shimmer)\n",
    "        aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "        apq11Shimmer_list.append(apq11Shimmer)\n",
    "        ddaShimmer_list.append(ddaShimmer)            \n",
    "        \n",
    "    \n",
    "    data = [file_list, speaker_list, gender_list, emotion_list, mfcc_list, ltas_mean_list, ltas_sd_list, ltas_max_list, ltas_min_list, ltas_range_list, ltas_slope_list, \n",
    "            f1_mean_list, f1_sd_list, f2_mean_list, f2_sd_list, f3_mean_list, f3_sd_list,\n",
    "            pitch_mean_list, pitch_sd_list, pitch_max_list, pitch_min_list, pitch_range_list,\n",
    "            intensity_mean_list, intensity_sd_list, intensity_max_list, intensity_min_list, intensity_range_list,\n",
    "            hnr_list, duration_list, localJitter_list, localabsoluteJitter_list, rapJitter_list, ppq5Jitter_list, ddpJitter_list, \n",
    "            localShimmer_list, localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, apq11Shimmer_list, ddaShimmer_list]\n",
    "    \n",
    "    # replace Nan value by 0\n",
    "    datax =[]\n",
    "    for list_data in data:      \n",
    "        in_arr = geek.array(list_data)\n",
    "        x = geek.nan_to_num(in_arr)\n",
    "        datax.append(x)\n",
    "        \n",
    "    df = pd.DataFrame(np.column_stack(datax), columns=['voiceID', 'speaker', 'gender', 'Emotion', 'MFCC 1', 'MFCC 2', 'MFCC 3', 'MFCC 4', 'MFCC 5', 'MFCC 6', 'MFCC 7', 'MFCC 8', 'MFCC 9', 'MFCC 10', 'MFCC 11', 'MFCC 12', \n",
    "                                                      'LTAS mean', 'LTAS stdev', 'LTAS max', 'LTAS min', 'LTAS range', 'LTAS slope', \n",
    "                                                      'Formant 1 mean', 'Formant 1 stdev', 'Formant 2 mean', 'Formant 2 stdev', 'Formant 3 mean', 'Formant 3 stdev', \n",
    "                                                      'Pitch mean', 'Pitch stdev', 'Pitch max', 'Pitch min', 'Pitch range', \n",
    "                                                      'Intensity mean', 'Intensity stdev', 'Intensity max', 'Intensity min', 'Intensity range', \n",
    "                                                      'HNR', 'Duration', 'local Jitter', 'local-absolute Jitter', 'rap Jitter', 'ppq5 Jitter', 'ddp Jitter', \n",
    "                                                      'local Shimmer', 'local-db Shimmer', 'apq3 Shimmer', 'apq5 Shimmer', 'apq11 Shimmer', 'dda Shimmer'])  #add these lists to pandas in the right order\n",
    "    \n",
    "    # calculate Jitter PCA \n",
    "    pcaJitterdf, jitterPCA = runPCA(df,\"jitter\")\n",
    "    df = pd.concat([df, pcaJitterdf], axis=1)\n",
    "    \n",
    "    for j in jitterPCA:\n",
    "        jitterpca_list.append(j[0])    \n",
    "    \n",
    "    # calculate Shimmer PCA     \n",
    "    pcaShimmerdf, shimmerPCA = runPCA(df,\"shimmer\")\n",
    "    df = pd.concat([df, pcaShimmerdf], axis=1)\n",
    "    for s in shimmerPCA:\n",
    "        shimmerpca_list.append(s[0])\n",
    "    \n",
    "  \n",
    "    # Write out the updated dataframe\n",
    "    #df.to_csv(\"EYASE (different value of pitch for each gender).csv\", index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51510c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 1.1815 minutes\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "extract_all_features()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Running time: {(toc - tic)/60:0.4f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9b882cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "def load_data(test_size):\n",
    "    x, y = [], []\n",
    "    for file in glob.glob(\"EYASE/*/*.wav\", recursive=True): #, recursive=True\n",
    "        # get the base name of the audio file\n",
    "        basename = os.path.basename(file)\n",
    "        # get the emotion label\n",
    "        emotion = allemotion[basename.split(\"_\")[1].split(\" \")[0]]\n",
    "        # get the gender label\n",
    "        gender = allgender[basename.split(\"_\")[0][0:2]]\n",
    "        # get the speaker label\n",
    "        speaker = basename.split(\"_\")[0][2:4]\n",
    "        # we allow only observed_emotions we set for both gender\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        if gender not in observed_gender:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # extract speech features\n",
    "        result = np.array([])\n",
    "        index = file_list.index(basename) #get features of each file by index\n",
    "        \n",
    "        file_name = file_list[index]\n",
    "        #\n",
    "        result = np.hstack((result, mfcc_list[index])) # mfcc\n",
    "        #result = np.hstack((result, mel_list[index])) # mel\n",
    "        \"\"\"\n",
    "        \n",
    "        result = np.hstack((result, ltas_mean_list[index])) # ltas_mean\n",
    "        result = np.hstack((result, ltas_sd_list[index])) # ltas_sd \n",
    "        result = np.hstack((result, ltas_max_list[index])) # ltas_max\n",
    "        result = np.hstack((result, ltas_min_list[index])) # ltas_min\n",
    "        result = np.hstack((result, ltas_range_list[index])) # ltas_range\n",
    "        result = np.hstack((result, ltas_slope_list[index])) # ltas_slope\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        result = np.hstack((result, f1_mean_list[index])) # f1_mean\n",
    "        result = np.hstack((result, f1_sd_list[index])) # f1_sd\n",
    "        result = np.hstack((result, f2_mean_list[index])) # f2_mean\n",
    "        result = np.hstack((result, f2_sd_list[index])) # f2_sd\n",
    "        result = np.hstack((result, f3_mean_list[index])) # f3_mean\n",
    "        result = np.hstack((result, f3_sd_list[index])) # f3_sd\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        result = np.hstack((result, pitch_mean_list[index])) # pitch_mean\n",
    "        result = np.hstack((result, pitch_sd_list[index])) # pitch_sd\n",
    "        result = np.hstack((result, pitch_max_list[index])) # pitch_max\n",
    "        result = np.hstack((result, pitch_min_list[index])) # pitch_min\n",
    "        result = np.hstack((result, pitch_range_list[index])) # pitch_range\n",
    "        \n",
    "        result = np.hstack((result, intensity_mean_list[index])) # intensity_mean\n",
    "        result = np.hstack((result, intensity_sd_list[index])) # intensity_sd\n",
    "        result = np.hstack((result, intensity_max_list[index])) # intensity_max\n",
    "        result = np.hstack((result, intensity_min_list[index])) # intensity_min\n",
    "        result = np.hstack((result, intensity_range_list[index])) # intensity_range\n",
    "\n",
    "        #result = np.hstack((result, hnr_list[index])) # hnr\n",
    "        #result = np.hstack((result, duration_list[index])) # duration\n",
    "               \n",
    "        result = np.hstack((result, localJitter_list[index])) #jitter\n",
    "        result = np.hstack((result, localabsoluteJitter_list[index])) #jitter\n",
    "        result = np.hstack((result, rapJitter_list[index])) #jitter\n",
    "        result = np.hstack((result, ppq5Jitter_list[index])) #jitter\n",
    "        result = np.hstack((result, ddpJitter_list[index])) #jitter\n",
    "        result = np.hstack((result, jitterpca_list[index])) #jitter       \n",
    "        \n",
    "        result = np.hstack((result, localShimmer_list[index])) #shimmer\n",
    "        result = np.hstack((result, localdbShimmer_list[index])) #shimmer\n",
    "        result = np.hstack((result, apq3Shimmer_list[index])) #shimmer\n",
    "        result = np.hstack((result, aqpq5Shimmer_list[index])) #shimmer\n",
    "        result = np.hstack((result, apq11Shimmer_list[index])) #shimmer\n",
    "        result = np.hstack((result, ddaShimmer_list[index])) #shimmer\n",
    "        result = np.hstack((result, shimmerpca_list[index])) #shimmer\n",
    "        \"\"\"\n",
    "        # # \n",
    "        \n",
    "        # add to data\n",
    "        x.append(result)\n",
    "        y.append(emotion)\n",
    "\n",
    "        \n",
    "    # replace Nan to 0\n",
    "    in_x = geek.array(x)\n",
    "    \n",
    "    out_x = geek.nan_to_num(in_x)\n",
    "    \n",
    "    return train_test_split(np.array(out_x), np.array(y), test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76e6ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebteh\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:611: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy first model: 83.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.83      0.83      0.83        29\n",
      "     neutral       0.84      0.84      0.84        31\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.83      0.83      0.83        60\n",
      "weighted avg       0.83      0.83      0.83        60\n",
      "\n",
      "[[24  5]\n",
      " [ 5 26]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebteh\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#loading_data\n",
    "x_train,x_test,y_train,y_test = load_data(test_size = 0.20)\n",
    "\n",
    "#FIRST MODEL\n",
    "model_params = {\n",
    "    'alpha': 0.01,\n",
    "    'batch_size': 256,\n",
    "    'epsilon': 1e-08, \n",
    "    'hidden_layer_sizes': (300,), \n",
    "    'learning_rate': 'adaptive', \n",
    "    'max_iter': 500, \n",
    "}\n",
    "    \n",
    "# initialize Multi Layer Perceptron classifier\n",
    "# with best parameters ( so far )\n",
    "model = MLPClassifier(**model_params)\n",
    "\n",
    "# train the model\n",
    "print(\"[*] Training the model...\")\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# predict 25% of data to measure how good we are\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy first model: {:.2f}%\".format(accuracy*100))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e21f58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training the model...\n",
      "Accuracy second model: 81.67%\n"
     ]
    }
   ],
   "source": [
    "#SECOND MODEL\n",
    "m_params = {\n",
    "    'alpha': 0.01,\n",
    "    'batch_size': 200,\n",
    "    'epsilon': 1e-08, \n",
    "    'hidden_layer_sizes': (300,), \n",
    "    'learning_rate': 'adaptive', \n",
    "    'max_iter': 500, \n",
    "}\n",
    "# initialize Multi Layer Perceptron classifier\n",
    "# with best parameters ( so far )\n",
    "m1 = MLPClassifier(**m_params)\n",
    "\n",
    "# train the model\n",
    "print(\"[*] Training the model...\")\n",
    "m1.fit(x_train, y_train)\n",
    "\n",
    "# predict 25% of data to measure how good we are\n",
    "y_p = m1.predict(x_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_p)\n",
    "\n",
    "print(\"Accuracy second model: {:.2f}%\".format(accuracy*100))\n",
    "#print(classification_report(y_test,y_p))\n",
    "#print(confusion_matrix(y_test,y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c703da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b8e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647bbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
